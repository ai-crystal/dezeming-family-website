import{_ as f,c as o,d as n,b as A,w as l,r,o as d,e as i}from"./app-MaooQpfW.js";const B={};function u(s,E){const p=r("VPIcon"),t=r("VPLink"),e=r("VPCard");return d(),o("div",null,[E[103]||(E[103]=n("p",{id:"OpenCV源码详解"},null,-1)),A(e,{title:"OpenCV源码详解",icon:""},{default:l(()=>[E[4]||(E[4]=n("p",null,"本专栏主要内容为OpenCV代码系统的构建原理，并不包含一些复杂功能的实现方案（比如Contrib里的高级算法实现原理）。由于Python用户基本上不需要了解OpenCV的底层运行机制，所以本栏目的编程语言主要为C/C++。更高级的算法功能原理实现会在“计算机视觉”的其他栏目中分别讲解和介绍。",-1)),E[5]||(E[5]=n("p",null,"由于OpenCV3的资料非常丰富，所以我们的讲解以OpenCV3为基础。OpenCV4虽然有不少变动，但主要集中在深度学习模块和一些底层指令集的优化，因此对于基础功能的应用来说并没有很大的改变，掌握好OpenCV3自然也能掌握好OpenCV4。",-1)),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[1]||(E[1]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%BD%BF%E7%94%A8OpenCV%E5%BF%85%E5%A4%87%E7%9F%A5%E8%AF%86%E7%82%B9C.pdf"},{default:l(()=>[...E[0]||(E[0]=[i("使用OpenCV必备知识点",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[3]||(E[3]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV%E7%9A%84%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%95%B0%E7%BB%84.pdf"},{default:l(()=>[...E[2]||(E[2]=[i("OpenCV的输入输出数组",-1)])]),_:1})]),E[6]||(E[6]=n("p",null,[n("strong",null,"参考资料")],-1)),E[7]||(E[7]=n("p",null,"[1] https://docs.opencv.org/",-1)),E[8]||(E[8]=n("p",null,`[2] Kaehler A, Bradski G. Learning OpenCV 3: computer vision in C++ with the OpenCV library[M]. " O'Reilly Media, Inc.", 2016.`,-1)),E[9]||(E[9]=n("p",null,"[3] Mordvintsev A, Abid K. Opencv-python tutorials documentation[J]. Obtenido de https://media. readthedocs. org/pdf/opencv-python-tutroals/latest/opencv-python-tutroals. pdf, 2014.",-1)),E[10]||(E[10]=n("p",null,"[4] https://docs.opencv.org/3.4.2/d1/dfb/intro.html",-1)),E[11]||(E[11]=n("p",null,"[5] https://docs.opencv.org/3.4.2/index.html",-1)),E[12]||(E[12]=n("p",null,"[6] https://github.com/opencv/opencv",-1)),E[13]||(E[13]=n("p",null,"[7] https://opencv.org/courses",-1))]),_:1}),E[104]||(E[104]=n("p",{id:"颜色空间理论"},null,-1)),A(e,{title:"颜色空间理论",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[15]||(E[15]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4%E7%90%86%E8%AE%BA.pdf"},{default:l(()=>[...E[14]||(E[14]=[i("颜色空间理论",-1)])]),_:1})])]),_:1}),E[105]||(E[105]=n("p",{id:"图像特征与特征匹配"},null,-1)),A(e,{title:"图像特征与特征匹配",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[17]||(E[17]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8BLOG%E4%B8%8EDOG%E5%8E%9F%E7%90%86%E4%B8%8EOpenCV%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98.pdf"},{default:l(()=>[...E[16]||(E[16]=[i("边缘检测LOG与DOG原理与OpenCV代码实战",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[19]||(E[19]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Harris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%8E%9F%E7%90%86%E4%B8%8EOpenCV%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB-1.pdf"},{default:l(()=>[...E[18]||(E[18]=[i("Harris角点检测原理与OpenCV源码解读-1",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[21]||(E[21]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Sift%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8EOpenCV%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB.pdf"},{default:l(()=>[...E[20]||(E[20]=[i("Sift算法原理与OpenCV源码解读",-1)])]),_:1})])]),_:1}),E[106]||(E[106]=n("p",{id:"图像质量评价"},null,-1)),A(e,{title:"图像质量评价（IQA）",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[23]||(E[23]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E6%A6%82%E8%A7%88.pdf"},{default:l(()=>[...E[22]||(E[22]=[i("图像质量评价概览",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[25]||(E[25]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/The-Unreasonable-Effectiveness-of-Deep-Features-as-a-Perceptual-Metric.pdf"},{default:l(()=>[...E[24]||(E[24]=[i("The-Unreasonable-Effectiveness-of-Deep-Features-as-a-Perceptual-Metric",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[27]||(E[27]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/MAPE%E5%92%8CsMAPE%E8%AF%AF%E5%B7%AE%E5%BA%A6%E9%87%8F.pdf"},{default:l(()=>[...E[26]||(E[26]=[i("MAPE和sMAPE误差度量",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[29]||(E[29]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/VMAF%E8%A7%86%E9%A2%91%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0.pdf"},{default:l(()=>[...E[28]||(E[28]=[i("VMAF视频质量评估",-1)])]),_:1})]),E[46]||(E[46]=n("p",null,[n("strong",null,"参考文献")],-1)),E[47]||(E[47]=n("p",null,"[1] Zhang R , Isola P , Efros A A , et al. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric[J]. IEEE, 2018.",-1)),E[48]||(E[48]=n("p",{id:"图像去噪与滤波"},null,-1)),A(e,{title:"图像去噪与滤波",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[31]||(E[31]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%99%AA%E5%A3%B0%E7%9A%84%E7%A7%8D%E7%B1%BB.pdf"},{default:l(()=>[...E[30]||(E[30]=[i("图像噪声的种类",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[33]||(E[33]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E4%B8%8E%E6%BB%A4%E6%B3%A2%E6%A6%82%E8%A7%88.pdf"},{default:l(()=>[...E[32]||(E[32]=[i("图像去噪与滤波概览",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[35]||(E[35]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%BC%95%E5%AF%BC%E6%BB%A4%E6%B3%A2%E5%8F%8A%E5%85%B6%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.pdf"},{default:l(()=>[...E[34]||(E[34]=[i("引导滤波及其代码实现",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[37]||(E[37]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%BF%AB%E9%80%9F%E5%BC%95%E5%AF%BC%E6%BB%A4%E6%B3%A2%E5%8F%8A%E5%85%B6%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.pdf"},{default:l(()=>[...E[36]||(E[36]=[i("快速引导滤波及其代码实现",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[39]||(E[39]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Paper%E9%98%85%E8%AF%BB-N2NLIR-2019-ICML.pdf"},{default:l(()=>[...E[38]||(E[38]=[i("Paper阅读-N2NLIR-2019-ICML",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[41]||(E[41]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Paper%E9%98%85%E8%AF%BB-N2VLD-2019-CVPR.pdf"},{default:l(()=>[...E[40]||(E[40]=[i("Paper阅读-N2VLD-2019-CVPR",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[43]||(E[43]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%8D%95%E5%B9%85%E5%9B%BE%E5%83%8F%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E5%85%88%E9%AA%8C%E7%9F%A5%E8%AF%86%E7%9A%84%E5%8E%BB%E9%9B%BE%E7%AE%97%E6%B3%95.pdf"},{default:l(()=>[...E[42]||(E[42]=[i("单幅图像基于暗通道先验知识的去雾算法",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[45]||(E[45]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%8D%95%E5%B9%85%E5%9B%BE%E5%83%8F%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E5%85%88%E9%AA%8C%E7%9F%A5%E8%AF%86%E7%9A%84%E5%8E%BB%E9%9B%BE%E7%AE%97%E6%B3%95-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.pdf"},{default:l(()=>[...E[44]||(E[44]=[i("单幅图像基于暗通道先验知识的去雾算法-代码实现",-1)])]),_:1})])]),_:1})]),_:1}),E[107]||(E[107]=n("p",{id:"图像分割（与边缘、轮廓提取）"},null,-1)),A(e,{title:"图像分割（与边缘、轮廓提取）",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[50]||(E[50]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%A6%82%E8%A6%81.pdf"},{default:l(()=>[...E[49]||(E[49]=[i("图像分割概要",-1)])]),_:1})])]),_:1}),E[108]||(E[108]=n("p",{id:"图像编辑（图像融合、抠图、图像增强等）"},null,-1)),A(e,{title:"图像编辑（图像融合、抠图、图像增强等）",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[52]||(E[52]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Poisson-image-editing.pdf"},{default:l(()=>[...E[51]||(E[51]=[i("Poisson Image Editing",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[54]||(E[54]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Poisson-image-editing-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-python%E7%89%88.pdf"},{default:l(()=>[...E[53]||(E[53]=[i("Poisson Image Editing 代码实现 - Python版",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[56]||(E[56]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8Fmatting%E7%9A%84%E9%97%AD%E5%BC%8F%E8%A7%A3-CVPR.pdf"},{default:l(()=>[...E[55]||(E[55]=[i("自然图像Matting的闭式解 - CVPR",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[58]||(E[58]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8Fmatting%E7%9A%84%E9%97%AD%E5%BC%8F%E8%A7%A3-TPAMI.pdf"},{default:l(()=>[...E[57]||(E[57]=[i("自然图像Matting的闭式解 - TPAMI",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[60]||(E[60]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8Fmatting%E7%9A%84%E9%97%AD%E5%BC%8F%E8%A7%A3-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.pdf"},{default:l(()=>[...E[59]||(E[59]=[i("自然图像Matting的闭式解 - 代码实现",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[62]||(E[62]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Paper%E9%98%85%E8%AF%BB-DBLGChen.pdf"},{default:l(()=>[...E[61]||(E[61]=[i("Paper阅读 - DBLG Chen",-1)])]),_:1})]),E[63]||(E[63]=n("p",null,[n("strong",null,"参考文献"),i(' Pérez, Patrick, Michel Gangnet, and Andrew Blake. "Poisson image editing." ACM SIGGRAPH 2003 Papers. 2003. 313-318.')],-1)),E[64]||(E[64]=n("p",null,"Sun, J., Jia, J., Tang, C. K., & Shum, H. Y. (2004). Poisson matting. In ACM SIGGRAPH 2004 Papers (pp. 315-321).",-1)),E[65]||(E[65]=n("p",null,'Levin, Anat, Dani Lischinski, and Yair Weiss. "A closed-form solution to natural image matting." IEEE transactions on pattern analysis and machine intelligence 30.2 (2007): 228-242.',-1)),E[66]||(E[66]=n("p",null,"Gharbi M , Chen J , Barron J T ,et al.Deep Bilateral Learning for Real-Time Image Enhancement[J].Acm Transactions on Graphics, 2017, 36(4):118.DOI:10.1145/3072959.3073592.",-1))]),_:1}),E[109]||(E[109]=n("p",{id:"目标定位与跟踪"},null,-1)),A(e,{title:"目标定位与跟踪",icon:""},{default:l(()=>[n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[68]||(E[68]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%89%E6%B5%81%E4%BC%B0%E8%AE%A1%E5%85%A5%E9%97%A8.pdf"},{default:l(()=>[...E[67]||(E[67]=[i("光流估计入门",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[70]||(E[70]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Horn%E2%80%93SchunckHS%E5%85%89%E6%B5%81%E6%B3%95.pdf"},{default:l(()=>[...E[69]||(E[69]=[i("Horn–SchunckHS光流法",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[72]||(E[72]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Lucas%E2%80%93KanadeLK%E5%85%89%E6%B5%81%E6%B3%95.pdf"},{default:l(()=>[...E[71]||(E[71]=[i("Lucas–KanadeLK光流法",-1)])]),_:1})])]),_:1}),E[110]||(E[110]=n("p",{id:"图像三维重建和三维理解"},null,-1)),A(e,{title:"图像三维重建和三维理解",icon:""},{default:l(()=>[E[77]||(E[77]=n("p",null,"特征点检测与匹配",-1)),E[78]||(E[78]=n("p",null,"SIFT，SURF，ORB等特征检测算法。LineMod：针对纹理少的场景。",-1)),E[79]||(E[79]=n("p",null,"基于图像的渲染(IBR, Image-based Rendering)",-1)),E[80]||(E[80]=n("p",null,"IBR 主要利用一组预先捕获的图像来生成新视角的图像，而不是依赖于详细的三维模型。这种技术特别适用于那些难以用传统三维建模方法表示的场景，这依赖于图像重投影和视图插值技术。",-1)),E[81]||(E[81]=n("p",null,"运动恢复结构(SFM, Structure from Motion)",-1)),E[82]||(E[82]=n("p",null,"SfM不要求实时性，对重建场景的精度要求更高；而SLAM要求实时性，对相机定位要求较高，但是对场景的稠密性要求比较低。",-1)),E[83]||(E[83]=n("p",null,"SfM可以用于恢复相机的内参、外参以及场景点云。",-1)),E[84]||(E[84]=n("p",null,"一些SFM工具： 传统的多视图几何内容已经基本被彻底研究透彻了。一些主流的离线视觉三维重建商业和开源的框架问世时间： 商用 ： · Photoscan（现在称为Agisoft Metashape）的首个版本于2010年发布。 · ContextCapture 是由Bentley Systems开发的软件，首个版本发布于2015年。 · Inpho 是由Trimble开发的软件，发布时间比较早，但具体时间可能因版本而异。Trimble公司在2008年收购了Inpho公司，因此在此之前的版本应该是由Inpho公司发布的。 · Pix4D是一家提供专业无人机图像处理软件的公司，其软件可用于生成高质量的地图和模型。Pix4D软件的首个版本于2011年发布。",-1)),E[85]||(E[85]=n("p",null,"开源： · openmvg 是2012年发布，应该是最早的且最具有代表性的三维重建框架。 · colmap是2016年发布的，一问世便处于巅峰位置，目前来看，仍然是处于incremental sfm 的榜首。 · 除了openmvg和colmap ，还有ODM、opensfm、theiasfm、alicevision等这些都差不多在colmap问世的前后时间。",-1)),E[86]||(E[86]=n("p",null,"目前来看，开源的大多数NeRF/3D GS框架的输入几乎都是colmap的SFM的结果（并不是NeRF/3D GS的输入必须是Colmap，也可以是vslam的结果也可以是一些商业软件的结果），使用colmap的原因很简单：开源SOTA且容易安装。",-1)),E[87]||(E[87]=n("p",null,"同时定位与制图(SLAM, Simultaneous Localization and Mapping)",-1)),E[88]||(E[88]=n("p",null,"SLAM同时定位与制图。定位的概念很好理解，如果一个机器人来到陌生的环境，它需要知道自己在哪儿，数学上来说就是知道自己的坐标，机器人如果在移动，就需要时刻的坐标更新。制图的意思是指对周围环境的了解，对周围环境的了解能帮助你更好地定位自己。",-1)),E[89]||(E[89]=n("p",null,"制图分为稀疏制图(sparse mapping)和稠密建图(dense mapping)。稀疏制图表示你对周围的环境只有部分的了解，而稠密建图则表示你对周围的环境的每一个点都清楚。",-1)),E[90]||(E[90]=n("p",null,"多视角立体(MVS, Multi-View Stereo)",-1)),E[91]||(E[91]=n("p",null,"多视角立体视觉(Multiple View Stereo, MVS)是对立体视觉的推广，能够在多个视角（从外向里）观察和获取景物的图像，并以此完成匹配和深度估计。",-1)),E[92]||(E[92]=n("p",null,"某种意义上讲，SLAM/SFM其实和MVS是类似的，只是前者是摄像头运动，后者是多个摄像头视角去观察一个物体。也可以说，SLAM/SFM像是在环境里面“穿行”，而MVS更像在环境外“旁观”。",-1)),E[93]||(E[93]=n("p",null,"逆渲染(Inverse Rendering)",-1)),E[94]||(E[94]=n("p",null,"逆渲染的目标: 图像->相机+几何+材质+光照+...等自然场景信息。三维重建可以算是逆渲染的一个子任务。逆渲染还在其他子任务，如光照估计，材质估计，位姿估计等。",-1)),E[95]||(E[95]=n("p",null,"深度估计(Depth Estimation)",-1)),E[96]||(E[96]=n("p",null,"深度估计可以认为是逆渲染中的一个子任务。先做深度估计再做",-1)),E[97]||(E[97]=n("p",null,"可微渲染(Differentiable Rendering)",-1)),E[98]||(E[98]=n("p",null,"可微渲染是逆渲染的一种解决方式。",-1)),E[99]||(E[99]=n("p",null,"可微渲染是可以微分求导的渲染过程，分为正向和逆向的过程。正向过程和传统渲染相同，输入模型和参数得到一张图片，逆向是像素对场景参数求导数。可微渲染不仅需要得到渲染结果，还要得到渲染结果（像素值）对输入参数的导数。传统的渲染方法不可微，所以可微渲染往往是基于某种传统渲染模型，通过引入新的技术，使得我们可以得到渲染结果对输入的导数。",-1)),E[100]||(E[100]=n("p",null,"主流的可微渲染方法往往基于以下两类思想，一类是使用近似的方法，求得近似导数用于反向传播；另一类是改编传统渲染模型，让像素对顶点可导。",-1)),E[101]||(E[101]=n("p",null,"上述第 1 类方法不改变传统渲染的正向过程，虽然传统渲染方法天然不可微，但使用近似的方法，能求得近似导数用于反向传播。 这类方法的核心在于如何更好地近似渲染过程的导数，使得导数在某种观点下是一种有效的近似，或是使得导数对优化输入有着指导意义。为了使得导数对优化输入有着指导意义，有时导数会和应用相关，会根据损失函数的不同而不同。",-1)),E[102]||(E[102]=n("p",null,"对于上述第 2 类方法，由于传统渲染方法天然不可微，需要对其进行改编，使得改编后的渲染方法依然拥有渲染的能力，渲染结果不发生较大变化，但其过程完全可微，可以求得精确导数。这类方法通常改编其中光栅化的步骤，因为这一步从连续空间映射到离散空间，是导致传统渲染不可微的原因。",-1)),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[74]||(E[74]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3.pdf"},{default:l(()=>[...E[73]||(E[73]=[i("相机标定入门详解",-1)])]),_:1})]),n("p",null,[A(p,{provider:"iconify",name:"ri:file-pdf-2-line"}),E[76]||(E[76]=i()),A(t,{href:"/pdfs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%B8%E6%9C%BA%E6%A3%8B%E7%9B%98%E6%A0%BC%E6%A0%87%E5%AE%9Apython-cv2%E7%9A%84%E5%AE%9E%E7%8E%B0.pdf"},{default:l(()=>[...E[75]||(E[75]=[i("相机棋盘格标定python-cv2的实现",-1)])]),_:1})])]),_:1})])}const C=f(B,[["render",u]]),g=JSON.parse('{"path":"/dezeming/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.html","title":"计算机视觉","lang":"en-US","frontmatter":{"title":"计算机视觉","tags":["计算机视觉"],"PageLayout":"custom","navbar":true,"aside":true,"outline":[2,4],"head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"计算机视觉\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-10-13T10:42:46.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://www.dezeming.top/dezeming/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.html"}],["meta",{"property":"og:site_name","content":"Dezeming Family"}],["meta",{"property":"og:title","content":"计算机视觉"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-10-13T10:42:46.000Z"}],["meta",{"property":"article:tag","content":"计算机视觉"}],["meta",{"property":"article:modified_time","content":"2025-10-13T10:42:46.000Z"}]]},"git":{"createdTime":1760257824000,"updatedTime":1760352166000,"contributors":[{"name":"threekd","username":"threekd","email":"threekd42@gmail.com","commits":5,"avatar":"https://avatars.githubusercontent.com/threekd?v=4","url":"https://github.com/threekd"}]},"filePathRelative":"dezeming/计算机视觉/计算机视觉.md","headers":[]}');export{C as comp,g as data};
