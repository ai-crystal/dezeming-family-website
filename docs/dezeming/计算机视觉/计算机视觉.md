---
title: 计算机视觉
tags:
  - 计算机视觉

PageLayout: 'custom' 
navbar: true
aside: true
outline: [2,4]
---

# 计算机视觉

{#OpenCV源码详解}
::: card title="OpenCV源码详解" icon=" "
本专栏主要内容为OpenCV代码系统的构建原理，并不包含一些复杂功能的实现方案（比如Contrib里的高级算法实现原理）。由于Python用户基本上不需要了解OpenCV的底层运行机制，所以本栏目的编程语言主要为C/C++。更高级的算法功能原理实现会在“计算机视觉”的其他栏目中分别讲解和介绍。

由于OpenCV3的资料非常丰富，所以我们的讲解以OpenCV3为基础。OpenCV4虽然有不少变动，但主要集中在深度学习模块和一些底层指令集的优化，因此对于基础功能的应用来说并没有很大的改变，掌握好OpenCV3自然也能掌握好OpenCV4。

::ri:file-pdf-2-line:: [使用OpenCV必备知识点](/pdfs/计算机视觉/使用OpenCV必备知识点C.pdf)

::ri:file-pdf-2-line:: [OpenCV的输入输出数组](/pdfs/计算机视觉/OpenCV的输入输出数组.pdf)

**参考资料**

[1] https://docs.opencv.org/

[2] Kaehler A, Bradski G. Learning OpenCV 3: computer vision in C++ with the OpenCV library[M]. " O'Reilly Media, Inc.", 2016.

[3] Mordvintsev A, Abid K. Opencv-python tutorials documentation[J]. Obtenido de https://media. readthedocs. org/pdf/opencv-python-tutroals/latest/opencv-python-tutroals. pdf, 2014.

[4] https://docs.opencv.org/3.4.2/d1/dfb/intro.html

[5] https://docs.opencv.org/3.4.2/index.html

[6] https://github.com/opencv/opencv

[7] https://opencv.org/courses

:::
{#颜色空间理论}
::: card title="颜色空间理论" icon=" "
::ri:file-pdf-2-line:: [颜色空间理论](/pdfs/计算机视觉/颜色空间理论.pdf)  
:::  
  
{#图像特征与特征匹配}
::: card title="图像特征与特征匹配" icon=" "  
::ri:file-pdf-2-line:: [边缘检测LOG与DOG原理与OpenCV代码实战](/pdfs/计算机视觉/边缘检测LOG与DOG原理与OpenCV代码实战.pdf)  
  
  
::ri:file-pdf-2-line:: [Harris角点检测原理与OpenCV源码解读-1](/pdfs/计算机视觉/Harris角点检测原理与OpenCV源码解读-1.pdf)  
  
  
::ri:file-pdf-2-line:: [Sift算法原理与OpenCV源码解读](/pdfs/计算机视觉/Sift算法原理与OpenCV源码解读.pdf)  
:::  
  
{#图像质量评价}
::: card title="图像质量评价（IQA）" icon=" "  
::ri:file-pdf-2-line:: [图像质量评价概览](/pdfs/计算机视觉/图像质量评价概览.pdf)  
  
  
::ri:file-pdf-2-line:: [The-Unreasonable-Effectiveness-of-Deep-Features-as-a-Perceptual-Metric](/pdfs/计算机视觉/The-Unreasonable-Effectiveness-of-Deep-Features-as-a-Perceptual-Metric.pdf)  
  
  
::ri:file-pdf-2-line:: [MAPE和sMAPE误差度量](/pdfs/计算机视觉/MAPE和sMAPE误差度量.pdf)  
  
  
::ri:file-pdf-2-line:: [VMAF视频质量评估](/pdfs/计算机视觉/VMAF视频质量评估.pdf)

**参考文献**

[1] Zhang R ,  Isola P ,  Efros A A , et al. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric[J]. IEEE, 2018. 

{#图像去噪与滤波}
::: card title="图像去噪与滤波" icon=" "
::ri:file-pdf-2-line:: [图像噪声的种类](/pdfs/计算机视觉/图像噪声的种类.pdf)  
  
  
::ri:file-pdf-2-line:: [图像去噪与滤波概览](/pdfs/计算机视觉/图像去噪与滤波概览.pdf)  
  
  
::ri:file-pdf-2-line:: [引导滤波及其代码实现](/pdfs/计算机视觉/引导滤波及其代码实现.pdf)  
  
  
::ri:file-pdf-2-line:: [快速引导滤波及其代码实现](/pdfs/计算机视觉/快速引导滤波及其代码实现.pdf)  
  
  
::ri:file-pdf-2-line:: [Paper阅读-N2NLIR-2019-ICML](/pdfs/计算机视觉/Paper阅读-N2NLIR-2019-ICML.pdf)  
  
  
::ri:file-pdf-2-line:: [Paper阅读-N2VLD-2019-CVPR](/pdfs/计算机视觉/Paper阅读-N2VLD-2019-CVPR.pdf)  
  
  
::ri:file-pdf-2-line:: [单幅图像基于暗通道先验知识的去雾算法](/pdfs/计算机视觉/单幅图像基于暗通道先验知识的去雾算法.pdf)  
  
  
::ri:file-pdf-2-line:: [单幅图像基于暗通道先验知识的去雾算法-代码实现](/pdfs/计算机视觉/单幅图像基于暗通道先验知识的去雾算法-代码实现.pdf)

:::

{#图像分割（与边缘、轮廓提取）}
::: card title="图像分割（与边缘、轮廓提取）" icon=" "
::ri:file-pdf-2-line:: [图像分割概要](/pdfs/计算机视觉/图像分割概要.pdf)
:::

{#图像编辑（图像融合、抠图、图像增强等）}
::: card title="图像编辑（图像融合、抠图、图像增强等）" icon=" "  
::ri:file-pdf-2-line:: [Poisson Image Editing](/pdfs/计算机视觉/Poisson-image-editing.pdf)  
  
  
::ri:file-pdf-2-line:: [Poisson Image Editing 代码实现 - Python版](/pdfs/计算机视觉/Poisson-image-editing-代码实现-python版.pdf)  
  
  
::ri:file-pdf-2-line:: [自然图像Matting的闭式解 - CVPR](/pdfs/计算机视觉/自然图像matting的闭式解-CVPR.pdf)  
  
  
::ri:file-pdf-2-line:: [自然图像Matting的闭式解 - TPAMI](/pdfs/计算机视觉/自然图像matting的闭式解-TPAMI.pdf)  
  
  
::ri:file-pdf-2-line:: [自然图像Matting的闭式解 - 代码实现](/pdfs/计算机视觉/自然图像matting的闭式解-代码实现.pdf)  
  
  
::ri:file-pdf-2-line:: [Paper阅读 - DBLG Chen](/pdfs/计算机视觉/Paper阅读-DBLGChen.pdf)

**参考文献**
Pérez, Patrick, Michel Gangnet, and Andrew Blake. "Poisson image editing." ACM SIGGRAPH 2003 Papers. 2003. 313-318.

Sun, J., Jia, J., Tang, C. K., & Shum, H. Y. (2004). Poisson matting. In ACM SIGGRAPH 2004 Papers (pp. 315-321).

Levin, Anat, Dani Lischinski, and Yair Weiss. "A closed-form solution to natural image matting." IEEE transactions on pattern analysis and machine intelligence 30.2 (2007): 228-242.

Gharbi M , Chen J , Barron J T ,et al.Deep Bilateral Learning for Real-Time Image Enhancement[J].Acm Transactions on Graphics, 2017, 36(4):118.DOI:10.1145/3072959.3073592.
:::
{#目标定位与跟踪}
::: card title="目标定位与跟踪" icon=" "
::ri:file-pdf-2-line:: [光流估计入门](/pdfs/计算机视觉/光流估计入门.pdf)

::ri:file-pdf-2-line:: [Horn–SchunckHS光流法](/pdfs/计算机视觉/Horn–SchunckHS光流法.pdf)

::ri:file-pdf-2-line:: [Lucas–KanadeLK光流法](/pdfs/计算机视觉/Lucas–KanadeLK光流法.pdf)

:::

{#图像三维重建和三维理解}
::: card title="图像三维重建和三维理解" icon=" "

特征点检测与匹配

SIFT，SURF，ORB等特征检测算法。LineMod：针对纹理少的场景。

基于图像的渲染(IBR, Image-based Rendering)

IBR 主要利用一组预先捕获的图像来生成新视角的图像，而不是依赖于详细的三维模型。这种技术特别适用于那些难以用传统三维建模方法表示的场景，这依赖于图像重投影和视图插值技术。

运动恢复结构(SFM, Structure from Motion)

SfM不要求实时性，对重建场景的精度要求更高；而SLAM要求实时性，对相机定位要求较高，但是对场景的稠密性要求比较低。

SfM可以用于恢复相机的内参、外参以及场景点云。

一些SFM工具：
传统的多视图几何内容已经基本被彻底研究透彻了。一些主流的离线视觉三维重建商业和开源的框架问世时间：
商用 ：
    · Photoscan（现在称为Agisoft Metashape）的首个版本于2010年发布。
    · ContextCapture 是由Bentley Systems开发的软件，首个版本发布于2015年。
    · Inpho 是由Trimble开发的软件，发布时间比较早，但具体时间可能因版本而异。Trimble公司在2008年收购了Inpho公司，因此在此之前的版本应该是由Inpho公司发布的。
    · Pix4D是一家提供专业无人机图像处理软件的公司，其软件可用于生成高质量的地图和模型。Pix4D软件的首个版本于2011年发布。

开源：
    · openmvg 是2012年发布，应该是最早的且最具有代表性的三维重建框架。
    · colmap是2016年发布的，一问世便处于巅峰位置，目前来看，仍然是处于incremental sfm 的榜首。
    · 除了openmvg和colmap ，还有ODM、opensfm、theiasfm、alicevision等这些都差不多在colmap问世的前后时间。

目前来看，开源的大多数NeRF/3D GS框架的输入几乎都是colmap的SFM的结果（并不是NeRF/3D GS的输入必须是Colmap，也可以是vslam的结果也可以是一些商业软件的结果），使用colmap的原因很简单：开源SOTA且容易安装。 

同时定位与制图(SLAM, Simultaneous Localization and Mapping)

SLAM同时定位与制图。定位的概念很好理解，如果一个机器人来到陌生的环境，它需要知道自己在哪儿，数学上来说就是知道自己的坐标，机器人如果在移动，就需要时刻的坐标更新。制图的意思是指对周围环境的了解，对周围环境的了解能帮助你更好地定位自己。

制图分为稀疏制图(sparse mapping)和稠密建图(dense mapping)。稀疏制图表示你对周围的环境只有部分的了解，而稠密建图则表示你对周围的环境的每一个点都清楚。


多视角立体(MVS, Multi-View Stereo)

多视角立体视觉(Multiple View Stereo, MVS)是对立体视觉的推广，能够在多个视角（从外向里）观察和获取景物的图像，并以此完成匹配和深度估计。

某种意义上讲，SLAM/SFM其实和MVS是类似的，只是前者是摄像头运动，后者是多个摄像头视角去观察一个物体。也可以说，SLAM/SFM像是在环境里面“穿行”，而MVS更像在环境外“旁观”。

逆渲染(Inverse Rendering)

逆渲染的目标: 图像->相机+几何+材质+光照+...等自然场景信息。三维重建可以算是逆渲染的一个子任务。逆渲染还在其他子任务，如光照估计，材质估计，位姿估计等。

深度估计(Depth Estimation)

深度估计可以认为是逆渲染中的一个子任务。先做深度估计再做

可微渲染(Differentiable Rendering)

可微渲染是逆渲染的一种解决方式。

可微渲染是可以微分求导的渲染过程，分为正向和逆向的过程。正向过程和传统渲染相同，输入模型和参数得到一张图片，逆向是像素对场景参数求导数。可微渲染不仅需要得到渲染结果，还要得到渲染结果（像素值）对输入参数的导数。传统的渲染方法不可微，所以可微渲染往往是基于某种传统渲染模型，通过引入新的技术，使得我们可以得到渲染结果对输入的导数。 

主流的可微渲染方法往往基于以下两类思想，一类是使用近似的方法，求得近似导数用于反向传播；另一类是改编传统渲染模型，让像素对顶点可导。

上述第 1 类方法不改变传统渲染的正向过程，虽然传统渲染方法天然不可微，但使用近似的方法，能求得近似导数用于反向传播。 这类方法的核心在于如何更好地近似渲染过程的导数，使得导数在某种观点下是一种有效的近似，或是使得导数对优化输入有着指导意义。为了使得导数对优化输入有着指导意义，有时导数会和应用相关，会根据损失函数的不同而不同。

对于上述第 2 类方法，由于传统渲染方法天然不可微，需要对其进行改编，使得改编后的渲染方法依然拥有渲染的能力，渲染结果不发生较大变化，但其过程完全可微，可以求得精确导数。这类方法通常改编其中光栅化的步骤，因为这一步从连续空间映射到离散空间，是导致传统渲染不可微的原因。

::ri:file-pdf-2-line:: [相机标定入门详解](/pdfs/计算机视觉/相机标定入门详解.pdf)

::ri:file-pdf-2-line:: [相机棋盘格标定python-cv2的实现](/pdfs/计算机视觉/相机棋盘格标定python-cv2的实现.pdf)


:::